{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614f6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.aptagen.com/aptamer-details/?id='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b06f4d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def saveHTML(url):\n",
    "    root = '/Users/jiamingxu/Downloads/Aptahtmls/'\n",
    "    urlroot = 'https://www.aptagen.com/'\n",
    "    if not os.path.exists(root):\n",
    "        os.mkdir(root)\n",
    "    os.chdir(root)\n",
    "    \n",
    "    if not os.path.exists('./images'):\n",
    "        os.mkdir('./images')\n",
    "        \n",
    "    try:\n",
    "        r = requests.get(url, headers={'user-agent':'Chrome/16.0'}, timeout=30)\n",
    "        r.raise_for_status\n",
    "        r.encoding = r.apparent_encoding\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        filenametitle = re.sub(r'/','-',soup.title.string.split(':')[-1])  # remove slash in title avoiding file creating error.\n",
    "        htmlfile = root + url.split('=')[-1] + '.' + filenametitle +  '.html'\n",
    "\n",
    "        if soup.title.string != 'Apta-Index:':\n",
    "            if not os.path.exists(htmlfile) or os.stat(htmlfile).st_size == 0:\n",
    "                with open(htmlfile, 'w') as f:\n",
    "                    f.write(r.text)\n",
    "                f.close()\n",
    "\n",
    "            # Save aptamer image        \n",
    "            for i in soup('img'):\n",
    "                try:\n",
    "                    if i['class'] == ['sequence-diagram']:\n",
    "                        img = requests.get('https://www.aptagen.com'+i['src'], headers={'user-agent':'Chrome/16.0'}, timeout=30)\n",
    "                        with open('./images/'+ url.split('=')[-1] + '.' +i['src'].split('.')[-1], 'wb') as imgf:\n",
    "                            imgf.write(img.content)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print(\"ERROR\"+str(url.split('=')[-1]))\n",
    "\n",
    "    \n",
    "def main():\n",
    "    url = 'https://www.aptagen.com/aptamer-details/?id='\n",
    "    for num in range(7250,7350):\n",
    "        saveHTML(url+str(num))\n",
    "        time.sleep(1)\n",
    "    print('Done')\n",
    "        \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa4393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c5c40a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getHTMLText(url):\n",
    "    try:\n",
    "        r = requests.get(url, headers={'user-agent':'Chrome/16.0'}, timeout=30)\n",
    "        r.raise_for_status\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "def parsePage(df, my_dict, html):\n",
    "    imgroot = '/Users/jiamingxu/Downloads/Aptahtmls/images/'\n",
    "    soup = BeautifulSoup(open(html), 'html.parser')\n",
    "    texts = open(html).read()\n",
    "    aptapat = re.compile(r'[r|f|d][A|G|C|T|U]p')\n",
    "    aptaseq = re.findall(aptapat, texts) \n",
    "    index = html.split('.')[0]\n",
    "    \n",
    "    for label in soup('label'):\n",
    "        if label.string:\n",
    "            my_dict[label.string] = label.next_sibling.next_sibling.string\n",
    "    my_dict['Title:'] = soup.title.string.split(':')[1]\n",
    "    my_dict['Reference:'] = soup.find('h3',{'itemprop':'description'}).string\n",
    "    my_dict['Sequence:'] = \",\".join(aptaseq)\n",
    "    # Searching for image under /images folder with specific pattern.\n",
    "    my_dict['Image'] = imgroot + re.search(r''+re.escape(str(index))+'.\\w*', ' '.join(os.listdir(imgroot))).group(0)\n",
    "    df = df.append(my_dict, ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def printAptaSeq(ilt):\n",
    "    tplt = '{:^30}\\t{:^40}'\n",
    "    print(tplt.format('Name','Sequence'))\n",
    "    for apta in ilt:\n",
    "        print(tplt.format(apta[0], apta[1]))\n",
    "    \n",
    "\n",
    "def main():\n",
    "    # Define diction for pandas.\n",
    "    my_dict = {'Title:':'',\n",
    "               'Aptamer Chemistry:':'', \n",
    "               'Image':'',\n",
    "               'Target:':'', \n",
    "               'Antigen/Target Category:':'', \n",
    "               'Affinity (Kd):':'', \n",
    "               'Binding Conditions/Buffer:':'', \n",
    "               'Binding Temp:':'', \n",
    "               'Refolding Program:':'', \n",
    "               'Specificity:':'', \n",
    "               'Molecular Weight:':'',\n",
    "               'GC Content:':'',\n",
    "               'Extinction Coefficient:':'',\n",
    "               'Ki:':'',\n",
    "               'LOD:':'',\n",
    "               'Comments:':'', \n",
    "               'Length:':'', \n",
    "               'Reference:':'',\n",
    "               'Sequence:':''} \n",
    "    \n",
    "    # Initialize pandas dataframe\n",
    "    df = pd.DataFrame(data=[], columns=list(my_dict))\n",
    "\n",
    "    for file in os.scandir():\n",
    "        if file.is_file:\n",
    "            try:\n",
    "                df = parsePage(df, my_dict, re.search(r'html$',file.name).string)\n",
    "            except:\n",
    "                pass\n",
    "            #parsePage(aptainfo, file.name)\n",
    "    return df\n",
    "\n",
    "df = main()\n",
    "df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ff046f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"120\" >'\n",
    "\n",
    "df.to_html('webpage.html', escape=False, formatters=dict(Image=path_to_image_html)) # Add html tag for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9d12f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AptamerDatabase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f0ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
